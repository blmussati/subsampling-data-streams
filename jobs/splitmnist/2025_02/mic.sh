#!/bin/bash

# Acquire 1 sample at time using method 'mic' (the version of Freddie). Each experiment is a different threshold (ie. number of training points to acquire and number of optimisations steps for a training loop)
# lr=0.03 which is the lr for which I got highest test accuracy in SplitMNIST when running with InfoRS workflow
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=10    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=20    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=50    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=100    acquisition.method=mic

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=10    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=20    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=50    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=100    acquisition.method=mic

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=10    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=20    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=50    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=100    acquisition.method=mic

# # Same experiments to above, but with lr=0.01. This is the lr that Freddie used for his experiments.
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=10    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=20    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=50    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=100    acquisition.method=mic

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=10    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=20    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=50    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=100    acquisition.method=mic

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=10    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=20    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=50    acquisition.method=mic
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=100    acquisition.method=mic

# # Baseline, acquire using 'random' but keeping all other hyperparams the same
# # lr = 0.03
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=10    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=20    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=50    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=100    acquisition.method=random

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=10    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=20    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=50    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=100    acquisition.method=random

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=10    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=20    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=50    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=100    acquisition.method=random

# # lr = 0.01
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=10    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=20    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=50    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=100    acquisition.method=random

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=10    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=20    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=50    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=100    acquisition.method=random

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=10    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=20    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=50    acquisition.method=random
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.target=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=100    acquisition.method=random

# Baseline, train on all traing data available, without acquiring points
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.train=-1    data.label_counts_main.target=0    data.label_counts_main.pool=0    data.label_counts_main.val=0    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=469    acquisition.n_train_labels_end=0
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.label_counts_main.train=-1    data.label_counts_main.target=0    data.label_counts_main.pool=0    data.label_counts_main.val.0.n_per_class=30    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=469    acquisition.n_train_labels_end=0
