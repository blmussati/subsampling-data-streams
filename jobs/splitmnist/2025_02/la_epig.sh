#!/bin/bash

# Acquire 1 sample at time using method 'la_epig' (label-aware EPIG). Each experiment is a different threshold (ie. number of training points to acquire and number of optimisations steps for a training loop)
# lr=0.03 -- highest test accuracy for SplitMNIST when running with InfoRS workflow
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=10    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=20    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=50    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=100    acquisition.method=la_epig

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=10    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=20    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=50    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=100    acquisition.method=la_epig

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=10    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=20    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=50    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=100    acquisition.method=la_epig

# # lr=0.01 -- the one that Freddie used for his experiments.
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=10    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=20    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=50    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=100    acquisition.method=la_epig

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=10    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=20    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=50    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=100    acquisition.method=la_epig

# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=10    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=20    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=50    acquisition.method=la_epig
# python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=100    acquisition.method=la_epig

# Baseline, acquire using 'epig' but keeping all other hyperparams the same
# lr = 0.03
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=10    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=20    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=50    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=100    acquisition.method=epig

python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=10    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=20    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=50    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=100    acquisition.method=epig

python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=10    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=20    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=50    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=100    acquisition.method=epig

# lr = 0.01
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=10    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=20    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=50    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=94    acquisition.n_train_labels_end=100    acquisition.method=epig

python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=10    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=20    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=50    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=1000    acquisition.n_train_labels_end=100    acquisition.method=epig

python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=10    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=20    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=50    acquisition.method=epig
python    cal.py    rng.seed=0    experiment_name=splitmnist_semi    data=splitmnist/embedding_curated    data.batch_sizes.train=128    model=pytorch_fc_net_mcdo_3layer    trainer=pytorch_neural_net_classif_mcdo    trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=10000    acquisition.n_train_labels_end=100    acquisition.method=epig
