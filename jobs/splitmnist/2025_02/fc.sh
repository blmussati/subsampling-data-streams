#!/bin/bash

# This is giving the same hyperparams to all selection function
# python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated   data.label_counts_main.target=0  data.batch_sizes.train=-1  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[100,100]  trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000  acquisition.method=mic      acquisition.n_train_labels_end=20,50,100  eval_every_acq_step=True
# python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated                                    data.batch_sizes.train=-1  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[100,100]  trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000  acquisition.method=la_epig  acquisition.n_train_labels_end=20,50,100  eval_every_acq_step=True
# python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated   data.label_counts_main.target=0  data.batch_sizes.train=-1  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[100,100]  trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000  acquisition.method=random   acquisition.n_train_labels_end=20,50,100  eval_every_acq_step=True

# This is giving best hyperparams settings for each selection function
python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated                                    data.batch_sizes.train=32  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[100,100]  trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.3     trainer.n_optim_steps_max=1000  acquisition.method=la_epig  acquisition.n_train_labels_end=20   eval_every_acq_step=True
python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated                                    data.batch_sizes.train=32  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[100,100]  trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000  acquisition.method=la_epig  acquisition.n_train_labels_end=50   eval_every_acq_step=True
python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated                                    data.batch_sizes.train=-1  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[100,100]  trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.3     trainer.n_optim_steps_max=500   acquisition.method=la_epig  acquisition.n_train_labels_end=100  eval_every_acq_step=True

python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated   data.label_counts_main.target=0  data.batch_sizes.train=32  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[100,100]  trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.3     trainer.n_optim_steps_max=1000  acquisition.method=random  acquisition.n_train_labels_end=20   eval_every_acq_step=True
python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated   data.label_counts_main.target=0  data.batch_sizes.train=32  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[100,100]  trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000  acquisition.method=random  acquisition.n_train_labels_end=50   eval_every_acq_step=True
python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated   data.label_counts_main.target=0  data.batch_sizes.train=-1  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[100,100]  trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.3     trainer.n_optim_steps_max=500   acquisition.method=random  acquisition.n_train_labels_end=100  eval_every_acq_step=True

python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated   data.label_counts_main.target=0  data.batch_sizes.train=-1  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[128,128,128]    trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.3     trainer.n_optim_steps_max=500   acquisition.method=mic  acquisition.n_train_labels_end=20   eval_every_acq_step=True
python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated   data.label_counts_main.target=0  data.batch_sizes.train=32  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[100,100]        trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.01    trainer.n_optim_steps_max=5000  acquisition.method=mic  acquisition.n_train_labels_end=50   eval_every_acq_step=True
python  cal.py  --multirun  rng.seed=range\(3\)  experiment_name=EmbSplitMNIST_FC data=splitmnist/embedding_curated   data.label_counts_main.target=0  data.batch_sizes.train=-1  model=pytorch_fc_net_mcdo_3layer  model.hidden_sizes=[100,100]        trainer=pytorch_neural_net_classif_mcdo  trainer.optimizer.lr=0.03    trainer.n_optim_steps_max=1000  acquisition.method=mic  acquisition.n_train_labels_end=100  eval_every_acq_step=True
